{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c893d92",
   "metadata": {},
   "source": [
    "All chat logs beside Q8 and Q7.4. can be found here (including a summary):\n",
    "https://chatgpt.com/share/a1b8a72e-bdd7-45d5-8e06-8de1e5790fc8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce00dacb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_n           0\n",
       "id              1\n",
       "name            0\n",
       "gender          0\n",
       "species         0\n",
       "birthday        0\n",
       "personality     0\n",
       "song           11\n",
       "phrase          0\n",
       "full_id         0\n",
       "url             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.\n",
    "\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b38b3b",
   "metadata": {},
   "source": [
    "1. \n",
    "This shows that the imported data has missing values because the function \"isna\" checks if each value is missing or availible and the code prints the sum of the missing values. Since there are number greater than zero, we know that there are missing values in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b875a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset has 391 rows and 11 columns.\n"
     ]
    }
   ],
   "source": [
    "#2.1\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "villagers_df = pd.read_csv(url)\n",
    "\n",
    "# Get the shape of the dataset (rows, columns)\n",
    "villagers_shape = villagers_df.shape\n",
    "\n",
    "print(f'This dataset has {villagers_shape[0]} rows and {villagers_shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d847618",
   "metadata": {},
   "source": [
    "2.2\n",
    "Observation refers to a single row, in my dataset observation refers to a villager from the game \"Animal Crossing\".\n",
    "Variable refers to a single column, in my dataset variable refers to a charactistic for the villagers in the game \"Animal Crossing\".\n",
    "The link to the chat logs with chatgpt with a summary at the end of it: https://chatgpt.com/share/a1b8a72e-bdd7-45d5-8e06-8de1e5790fc8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a4a9ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive Statistics for Numeric Columns:\n",
      "             row_n\n",
      "count  391.000000\n",
      "mean   239.902813\n",
      "std    140.702672\n",
      "min      2.000000\n",
      "25%    117.500000\n",
      "50%    240.000000\n",
      "75%    363.500000\n",
      "max    483.000000\n",
      "\n",
      "Counts of Unique Values in Categorical Columns:\n",
      "\n",
      "Column: id\n",
      "id\n",
      "admiral    1\n",
      "mott       1\n",
      "paula      1\n",
      "patty      1\n",
      "pate       1\n",
      "          ..\n",
      "eloise     1\n",
      "elmer      1\n",
      "ellie      1\n",
      "elise      1\n",
      "zucker     1\n",
      "Name: count, Length: 390, dtype: int64\n",
      "\n",
      "Column: name\n",
      "name\n",
      "Admiral    1\n",
      "Muffy      1\n",
      "Paula      1\n",
      "Patty      1\n",
      "Pate       1\n",
      "          ..\n",
      "Elvis      1\n",
      "Eloise     1\n",
      "Elmer      1\n",
      "Ellie      1\n",
      "Zucker     1\n",
      "Name: count, Length: 391, dtype: int64\n",
      "\n",
      "Column: gender\n",
      "gender\n",
      "male      204\n",
      "female    187\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: species\n",
      "species\n",
      "cat          23\n",
      "rabbit       20\n",
      "frog         18\n",
      "squirrel     18\n",
      "duck         17\n",
      "dog          16\n",
      "cub          16\n",
      "pig          15\n",
      "bear         15\n",
      "mouse        15\n",
      "horse        15\n",
      "bird         13\n",
      "penguin      13\n",
      "sheep        13\n",
      "elephant     11\n",
      "wolf         11\n",
      "ostrich      10\n",
      "deer         10\n",
      "eagle         9\n",
      "gorilla       9\n",
      "chicken       9\n",
      "koala         9\n",
      "goat          8\n",
      "hamster       8\n",
      "kangaroo      8\n",
      "monkey        8\n",
      "anteater      7\n",
      "hippo         7\n",
      "tiger         7\n",
      "alligator     7\n",
      "lion          7\n",
      "bull          6\n",
      "rhino         6\n",
      "cow           4\n",
      "octopus       3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: birthday\n",
      "birthday\n",
      "1-27     2\n",
      "12-5     2\n",
      "7-31     2\n",
      "3-26     2\n",
      "8-3      2\n",
      "        ..\n",
      "4-3      1\n",
      "10-26    1\n",
      "7-23     1\n",
      "12-8     1\n",
      "3-8      1\n",
      "Name: count, Length: 361, dtype: int64\n",
      "\n",
      "Column: personality\n",
      "personality\n",
      "lazy      60\n",
      "normal    59\n",
      "cranky    55\n",
      "snooty    55\n",
      "jock      55\n",
      "peppy     49\n",
      "smug      34\n",
      "uchi      24\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: song\n",
      "song\n",
      "K.K. Country     10\n",
      "Forest Life       9\n",
      "Imperial K.K.     7\n",
      "K.K. Soul         7\n",
      "K.K. Ragtime      7\n",
      "                 ..\n",
      "Aloha K.K.        2\n",
      "Drivin'           1\n",
      "Senor K.K.        1\n",
      "K.K.  Bazaar      1\n",
      "K.K. D&B          1\n",
      "Name: count, Length: 92, dtype: int64\n",
      "\n",
      "Column: phrase\n",
      "phrase\n",
      "wee one       2\n",
      "quacko        2\n",
      "bloop         2\n",
      "aye aye       1\n",
      "snoot         1\n",
      "             ..\n",
      "lambchop      1\n",
      "yeah buddy    1\n",
      "chow down     1\n",
      "unh-hunh      1\n",
      "pronk         1\n",
      "Name: count, Length: 388, dtype: int64\n",
      "\n",
      "Column: full_id\n",
      "full_id\n",
      "villager-admiral    1\n",
      "villager-muffy      1\n",
      "villager-paula      1\n",
      "villager-patty      1\n",
      "villager-pate       1\n",
      "                   ..\n",
      "villager-elvis      1\n",
      "villager-eloise     1\n",
      "villager-elmer      1\n",
      "villager-ellie      1\n",
      "villager-zucker     1\n",
      "Name: count, Length: 391, dtype: int64\n",
      "\n",
      "Column: url\n",
      "url\n",
      "https://villagerdb.com/images/villagers/thumb/admiral.98206ee.png    1\n",
      "https://villagerdb.com/images/villagers/thumb/muffy.1497c92.png      1\n",
      "https://villagerdb.com/images/villagers/thumb/paula.563ba81.png      1\n",
      "https://villagerdb.com/images/villagers/thumb/patty.3e17f7f.png      1\n",
      "https://villagerdb.com/images/villagers/thumb/pate.c60838c.png       1\n",
      "                                                                    ..\n",
      "https://villagerdb.com/images/villagers/thumb/elvis.57d4757.png      1\n",
      "https://villagerdb.com/images/villagers/thumb/eloise.112208b.png     1\n",
      "https://villagerdb.com/images/villagers/thumb/elmer.cc7df52.png      1\n",
      "https://villagerdb.com/images/villagers/thumb/ellie.5a144a6.png      1\n",
      "https://villagerdb.com/images/villagers/thumb/zucker.8dbb719.png     1\n",
      "Name: count, Length: 391, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#3.\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "villagers_df = pd.read_csv(url)\n",
    "\n",
    "# Display descriptive statistics for numerical columns\n",
    "numeric_summary = villagers_df.describe()\n",
    "\n",
    "# Display counts of unique values in each categorical column\n",
    "categorical_summary = {col: villagers_df[col].value_counts() for col in villagers_df.columns if villagers_df[col].dtype == 'object'}\n",
    "\n",
    "# Print the summaries\n",
    "print(\"Descriptive Statistics for Numeric Columns:\\n\", numeric_summary)\n",
    "print(\"\\nCounts of Unique Values in Categorical Columns:\")\n",
    "for col, counts in categorical_summary.items():\n",
    "    print(f\"\\nColumn: {col}\\n{counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "938439df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset (rows, columns): (891, 15)\n",
      "\n",
      "Descriptive statistics for numerical columns:\n",
      "          survived      pclass         age       sibsp       parch        fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n"
     ]
    }
   ],
   "source": [
    "#4.\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "titanic= \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "titanic_df = pd.read_csv(titanic)\n",
    "\n",
    "# Get the shape of the dataset (total number of rows and columns)\n",
    "shape = titanic_df.shape\n",
    "\n",
    "# Get the descriptive statistics for numerical columns\n",
    "describe = titanic_df.describe()\n",
    "\n",
    "# Print the results\n",
    "print(\"Shape of the dataset (rows, columns):\", shape)\n",
    "print(\"\\nDescriptive statistics for numerical columns:\\n\", describe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8446c9",
   "metadata": {},
   "source": [
    "Using this code we can see the the column age only has 714 data points, however, we know by seeing the shape that there should be 891. Therefore the column age is missing 177 data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d0bcf6",
   "metadata": {},
   "source": [
    "5.\n",
    "Attribute: Represents a characteristic or the state of an object or thing.\n",
    "Method: Is a function which shows what actions the object or thing can do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3241d675",
   "metadata": {},
   "source": [
    "6.(copied from chatgpt)\n",
    "\n",
    "count: The number of non-null (non-missing) values in the column.\n",
    "mean: The average value of the column.\n",
    "std: The standard deviation, which measures the spread of the data around the mean.\n",
    "min: The minimum value in the column.\n",
    "25% (1st quartile): The value at the 25th percentile, meaning 25% of the data lies below this value.\n",
    "50% (median): The median value, which is the middle value when the data is sorted.\n",
    "75% (3rd quartile): The value at the 75th percentile, meaning 75% of the data lies below this value.\n",
    "max: The maximum value in the column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e5df4c",
   "metadata": {},
   "source": [
    "7.1. A case that df.dropna() would be preferreed instead of del df['col'] is when we need to remove rows with missing data in muliple columns. For example, if a row from a survey taker did not answer 1 or more questions, the data shown could be influenced by the people who did answer all the questions, therefore it would be better to use only people who answered all the question to have equal amounts of answers for each catergory. \n",
    "\n",
    "7.2. A case that del df['col'] would be preffered instead of df.dropna() would be when you have a column that is unneccesary is is often blank. For example, if a question like \"What's you favourite animal?\" is often left blank, that column may need to be removed as there is no need to have it as it may be less important compared to other questions.\n",
    "\n",
    "7.3. When both del df['col'] and df.dropna() are going to be used, would be better to use del df['col'] before df.dropna() because if a column or multiple columns are commonly missing values, then we would want to delete them because if we dropped the rows first we would lose a lot more rows than one or a few columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15088269",
   "metadata": {},
   "source": [
    "7.4. The approach I use in the following code uses only df['col'] since in my url there are only 4 columns that have missing data \"age\", \"embarked\", \"deck\", and embarked_town\".\n",
    "\n",
    "The chat with Chatgpt for this question(7.4.):\n",
    "https://chatgpt.com/share/c1331f78-7e0a-491a-872a-e378cd83f312"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "373f5ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data before cleaning:\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n",
      "\n",
      "Missing data after cleaning:\n",
      "survived      0\n",
      "pclass        0\n",
      "sex           0\n",
      "sibsp         0\n",
      "parch         0\n",
      "fare          0\n",
      "class         0\n",
      "who           0\n",
      "adult_male    0\n",
      "alive         0\n",
      "alone         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Check for missing data before cleaning\n",
    "missing_data_before = df.isnull().sum()\n",
    "print(\"Missing data before cleaning:\")\n",
    "print(missing_data_before)\n",
    "\n",
    "# Remove columns with any missing values\n",
    "for col in df.columns:\n",
    "    if df[col].isnull().any():\n",
    "        del df[col]\n",
    "\n",
    "# Check for missing data after cleaning\n",
    "missing_data_after = df.isnull().sum()\n",
    "print(\"\\nMissing data after cleaning:\")\n",
    "print(missing_data_after)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd26af1e",
   "metadata": {},
   "source": [
    "8.1. The chatgpt chat log for all of Q8. can be found here(including a summary at the end): \n",
    "https://chatgpt.com/share/ce68c70c-fff8-464f-87de-b9e9d4f7c542\n",
    "\n",
    "I asked python to explain to me what df.groupby(\"col1\")[\"col2\"].describe() does and an example I have used is taking \"pclass\" as \"col1\" and \"survived\" as \"col2\" from the file \"titanic\" to compare these 2 columns which shows the closer to 1st pclass the better your survivle rate would be on the titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a982a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count      mean       std  min  25%  50%  75%  max\n",
      "pclass                                                    \n",
      "1       216.0  0.629630  0.484026  0.0  0.0  1.0  1.0  1.0\n",
      "2       184.0  0.472826  0.500623  0.0  0.0  0.0  1.0  1.0\n",
      "3       491.0  0.242363  0.428949  0.0  0.0  0.0  0.0  1.0\n"
     ]
    }
   ],
   "source": [
    "#This is the code I changed for my example\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by 'pclass' and describe the 'survived' column\n",
    "grouped_stats = df.groupby(\"pclass\")[\"survived\"].describe()\n",
    "print(grouped_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be048475",
   "metadata": {},
   "source": [
    "8.2. The count in df.describe() shows the count for all the non-null values in that column, however df.groupby(\"col1\")[\"col2\"].describe() counts how many non-null values from \"col2\" defined by \"col1\" there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4964c83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#8.3.A. \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the dataset from the URL\u001b[39;00m\n\u001b[1;32m      4\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitanic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(url)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Get the shape of the dataset (rows, columns)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m titanic_shape \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#8.3.A. \n",
    "\n",
    "# Load the dataset from the URL\n",
    "url = \"titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Get the shape of the dataset (rows, columns)\n",
    "titanic_shape = df.shape\n",
    "\n",
    "print(f'This dataset has {titanic_shape[0]} rows and {titanic_shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1515423",
   "metadata": {},
   "source": [
    "After the first time entering the error into chatgpt, clearly shows its better than google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9341a3dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'titanics.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load the Titanic dataset\u001b[39;00m\n\u001b[1;32m      6\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitanics.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Get the shape of the dataset (rows, columns)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m titanic_shape \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'titanics.csv'"
     ]
    }
   ],
   "source": [
    "#8.3.B. \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"titanics.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Get the shape of the dataset (rows, columns)\n",
    "titanic_shape = df.shape\n",
    "\n",
    "print(f'This dataset has {titanic_shape[0]} rows and {titanic_shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a02ef1",
   "metadata": {},
   "source": [
    "In the chatgpt logs it shows that it says that mispelling the file is a possibility, which would then make the user(me) check if it was spelled correctly, which is better than google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c656417",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Get the shape of the dataset (rows, columns)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m titanic_shape \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 11\u001b[0m \u001b[43mDF\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpclass\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msurvived\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DF' is not defined"
     ]
    }
   ],
   "source": [
    "#8.3.C. \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Get the shape of the dataset (rows, columns)\n",
    "titanic_shape = df.shape\n",
    "DF.groupby(\"pclass\")[\"survived\"].describe()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93b47a0",
   "metadata": {},
   "source": [
    "Once again, chatgpt is telling me that the variable should be df which is a lot better than any google searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9b557b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (2551714266.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    df = pd.read_csv(url\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "#8.3.D. \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"titanics.csv\"\n",
    "df = pd.read_csv(url\n",
    "\n",
    "# Get the shape of the dataset (rows, columns)\n",
    "titanic_shape = df.shape\n",
    "\n",
    "print(f'This dataset has {titanic_shape[0]} rows and {titanic_shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d34208",
   "metadata": {},
   "source": [
    "Chat gpt told me exactly what to do to fix this, but google also said how to say it in my first search. However, chatgpt gave me an example of code to fix it, which google did not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a040854",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SeriesGroupBy' object has no attribute 'describle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Get the shape of the dataset (rows, columns)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m titanic_shape \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 12\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpclass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msurvived\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescrible\u001b[49m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1312\u001b[0m, in \u001b[0;36mGroupBy.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m   1309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[1;32m   1310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[attr]\n\u001b[0;32m-> 1312\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1314\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SeriesGroupBy' object has no attribute 'describle'"
     ]
    }
   ],
   "source": [
    "#8.3.E.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Get the shape of the dataset (rows, columns)\n",
    "titanic_shape = df.shape\n",
    "df.groupby('pclass')[\"survived\"].describle()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec06ef46",
   "metadata": {},
   "source": [
    "Chat gpt tells me that the correct method is .describe() instead of .describle(). Google makes me look through websites to evnetually fine that the method is .describe() not .describle()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9c0650f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Sex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Get the shape of the dataset (rows, columns)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m titanic_shape \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 11\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:8869\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   8866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   8867\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 8869\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   8870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8872\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8875\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1278\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1278\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/grouper.py:1009\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1009\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Sex'"
     ]
    }
   ],
   "source": [
    "#8.3.F.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Get the shape of the dataset (rows, columns)\n",
    "titanic_shape = df.shape\n",
    "df.groupby(\"Sex\")[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9231f7",
   "metadata": {},
   "source": [
    "Chatgpt once again tells me that i probably have misspelled this while google just tells me I need to put a column name there instead of \"Sex\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2dfe3006",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sex' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Get the shape of the dataset (rows, columns)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m titanic_shape \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 11\u001b[0m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[43msex\u001b[49m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sex' is not defined"
     ]
    }
   ],
   "source": [
    "#8.3.G.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Get the shape of the dataset (rows, columns)\n",
    "titanic_shape = df.shape\n",
    "df.groupby(sex)[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667a5072",
   "metadata": {},
   "source": [
    "Chatgpt then tells me to make it \"Sex\" however this wouldn't work but if I put that into chatgpt it would result as the same answer for 8.3.F. which is still better than google.\n",
    "\n",
    "9. Somewhat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
